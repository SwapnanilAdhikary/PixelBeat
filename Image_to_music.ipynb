{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21405eaa-75f3-4b34-8e61-feeba2344a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8e0e532-843d-4de4-9ff3-585fd16ba6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc2').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00e06e11-9862-4135-a48c-f90ac6ddf93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_data = image.img_to_array(img)\n",
    "    img_data = np.expand_dims(img_data, axis=0)\n",
    "    img_data = preprocess_input(img_data)\n",
    "    \n",
    "    vgg16_feature = model.predict(img_data)\n",
    "    return vgg16_feature.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4bebaab-7b8b-47fc-991a-e534d6f858b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 770ms/step\n",
      "(4096,)\n"
     ]
    }
   ],
   "source": [
    "img_features = extract_features(\"C:\\\\Users\\\\adhik\\\\Downloads\\\\test.jpg\")\n",
    "print(img_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a585429-36f1-4376-b7bb-dc05e0352265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize image features to fit the musical range (e.g., 60-80 for MIDI pitch)\n",
    "def normalize_features(features, min_val, max_val):\n",
    "    # Prevent division by zero if features have constant values\n",
    "    if np.min(features) == np.max(features):\n",
    "        return np.full(features.shape, (min_val + max_val) / 2)\n",
    "    \n",
    "    normalized = (features - np.min(features)) / (np.max(features) - np.min(features))\n",
    "    \n",
    "    # Ensure no NaN values and handle edge cases\n",
    "    normalized = np.nan_to_num(normalized)  # Replace NaN with 0\n",
    "    return normalized * (max_val - min_val) + min_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69f6b10c-dc31-4f4f-8143-3d294f574ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping image features to MIDI notes and durations\n",
    "def map_features_to_music(features):\n",
    "    # Select first 10 features for pitches and next 10 for durations\n",
    "    pitches = normalize_features(features[:10], 60, 80)  # MIDI pitches between 60 and 80\n",
    "    durations = normalize_features(features[10:20], 0.5, 2)  # Durations between 0.5 and 2 seconds\n",
    "    \n",
    "    # Convert to integers (for pitches) and ensure no NaN values\n",
    "    pitches = np.nan_to_num(pitches).astype(int)  # Replace NaN with 0 for safety\n",
    "    durations = np.nan_to_num(durations)  # Replace NaN with 0 for safety\n",
    "    \n",
    "    return pitches, durations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2bac823-432f-49e2-bab0-797de79d9ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from midiutil import MIDIFile\n",
    "def create_midi(pitches, durations, file_name=\"output_music.mid\"):\n",
    "    midi = MIDIFile(1) \n",
    "    track = 0\n",
    "    time = 0\n",
    "    midi.addTrackName(track, time, \"Generated Track\")\n",
    "    midi.addTempo(track, time, 120)  # Set the tempo\n",
    "\n",
    "    channel = 0\n",
    "    volume = 100\n",
    "\n",
    "    for i in range(len(pitches)):\n",
    "        midi.addNote(track, channel, pitches[i], time, durations[i], volume)\n",
    "        time += durations[i]  # Move time forward\n",
    "\n",
    "   \n",
    "    with open(file_name, \"wb\") as output_file:\n",
    "        midi.writeFile(output_file)\n",
    "\n",
    "pitches, durations = map_features_to_music(img_features)\n",
    "create_midi(pitches, durations, \"image_to_music.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88fdefdc-b426-4240-9cc2-7cda44f8e4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_music(img_path, output_midi=\"output_music.mid\"):\n",
    "    features = extract_features(img_path)\n",
    "    pitches, durations = map_features_to_music(features)\n",
    "    create_midi(pitches, durations, output_midi)\n",
    "    print(f\"Music generated and saved to {output_midi}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d79855a-c02a-4c96-bf25-8d5f17dd61a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step\n",
      "Music generated and saved to generated_music.mid\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_to_music(\"C:\\\\Users\\\\adhik\\\\Downloads\\\\test2.jpg\", 'generated_music.mid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064d06b1-dcc7-4601-8efc-999ed581ba12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
